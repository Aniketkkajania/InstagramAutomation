{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a185179",
   "metadata": {},
   "source": [
    "### First TASK (LOGIN FUNCTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0604b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "chromedriver_autoinstaller.install()\n",
    "sample_username = 'USERNAME'\n",
    "sample_psw = 'PASSWORD'\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "def login(sample_user, sample_pswd, driver):\n",
    "    driver.get(\"https://instagram.com\")\n",
    "    time.sleep(3)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    user = driver.find_elements(By.XPATH, '//input[contains(@class, \"_aa4b _add6 _ac4d\")]')[0]\n",
    "    psw = driver.find_elements(By.XPATH, '//input[contains(@class, \"_aa4b _add6 _ac4d\")]')[1]\n",
    "    \n",
    "    user.send_keys(sample_username)\n",
    "    psw.send_keys(sample_psw)\n",
    "    login = driver.find_element(By.XPATH, '//button[contains(@class, \"_acan _acap _acas _aj1-\")]')\n",
    "    login.click()\n",
    "\n",
    "login(sample_username, sample_psw, driver)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d81e449",
   "metadata": {},
   "source": [
    "### Second TASK (SEARCH FOOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2f69938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_tour_ent\n",
      "bhopalfoodwalks\n",
      "bhopalfoodlovers\n",
      "indian_tasty_food\n",
      "streetfoodbhopal\n",
      "indore_streetfood\n",
      "food\n",
      "travelbitess\n",
      "_foodie.af_\n",
      "bhopalfoodgram\n",
      "foodenza_bhopal\n",
      "food_street_indore\n",
      "indori_foodiess\n",
      "bhopalifoodguru\n",
      "chocoheaven_deeply_divine\n",
      "bhopali_foodies_\n",
      "food_vlogs_and_recipes\n",
      "food_blog_bhopal\n",
      "foodpharmerVerified\n",
      "maldives.exploresVerified\n",
      "china.travelsVerified\n",
      "kawalpreet_kaur_kalsi\n",
      "__vaishali_sharma\n",
      "usa.exploresVerified\n",
      "explorer_bhaiya\n",
      "roamingferalcat\n",
      "bhookh_bakar_baithak\n",
      "_food.is.good._\n",
      "ganeshamfastfoodbhopal\n",
      "dietitiandeanna\n",
      "__food.fanatic__\n",
      "indorefooddelicacy\n",
      "Food Court in DB City\n",
      "rays.indorefoodcourt\n",
      "food_unlock_official\n",
      "japan.exploresVerified\n",
      "thailand.exploresVerified\n",
      "Food Craft Restaurant\n",
      "indorefoodexplorer\n",
      "foodtemptationsbhopal\n",
      "miami.explorersVerified\n",
      "paragbakery_and_fast_food\n",
      "foodie_batra\n",
      "chai_ke_aashik\n",
      "foodie_traveler___\n",
      "ZauQ - Food Factory\n",
      "food_prismmm\n",
      "ishita_neema\n"
     ]
    }
   ],
   "source": [
    "def search(query, driver):\n",
    "    srch_button = driver.find_elements(By.CLASS_NAME, '_ab6-')[2]\n",
    "    srch_button.click()\n",
    "    srch_text = driver.find_element(By.XPATH, '//div//input[@aria-label=\"Search input\"]')\n",
    "    srch_text.send_keys(query) \n",
    "    time.sleep(4)\n",
    "    \n",
    "    # Extracting all ig handles that comes when we search food or any query\n",
    "    all_ig_handles = driver.find_elements(By.XPATH, '//div[contains(@class, \"x9f619 xjbqb8w x78zum5 x168nmei x13lgxp2 x5pf9jr xo71vjh x1uhb9sk x1plvlek xryxfnj x1iyjqo2 x2lwn1j xeuugli xdt5ytf xqjyukv x1cy8zhl x1oa3qoh x1nhvcw1\")]')\n",
    "\n",
    "    #printing all ig handles\n",
    "    for x in all_ig_handles[:-4]:\n",
    "        html = x.get_attribute('innerHTML')\n",
    "        data = bs(html, \"html.parser\")\n",
    "        txt_data = data.span.text.strip()\n",
    "        if \"#\" not in txt_data:\n",
    "            print(txt_data)\n",
    "    driver.find_elements(By.CLASS_NAME, \"_ab6-\")[0].click()\n",
    "query = 'food'\n",
    "search(query, driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a135df0d",
   "metadata": {},
   "source": [
    "### THIRD TASK OPENING PROFILE OF ANY SEARCH QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b1e4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_user(query, driver):\n",
    "    srch_button = driver.find_elements(By.CLASS_NAME, '_ab6-')[2]\n",
    "    srch_button.click()\n",
    "    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\n",
    "                                                    '//div[contains(@class, \"_aaw6\")]')))\n",
    "    \n",
    "    \n",
    "    srch_text = driver.find_element(By.XPATH, '//div//input[@aria-label=\"Search input\"]')\n",
    "    srch_text.send_keys(query)\n",
    "    \n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, f'//span[text()=\"{query}\"]')))\n",
    "    \n",
    "    driver.find_element(By.XPATH, f'//span[text()=\"{query}\"]').click()\n",
    "    \n",
    "search_user(\"sodelhi\", driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d4032",
   "metadata": {},
   "source": [
    "### FOURTH TASK  (FOLLOW UNFOLLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aab033ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfollowed\n"
     ]
    }
   ],
   "source": [
    "def follow_unfollow(handle_name, driver, params):\n",
    "    search_user(handle_name, driver)\n",
    "    time.sleep(5)\n",
    "    follow = driver.find_element(By.XPATH, '//div[contains(@class, \"_aacl _aaco _aacw _aad6 _aade\")]')\n",
    "    html = follow.get_attribute('innerHTML')\n",
    "    data = bs(html, \"html.parser\")\n",
    "    if params == 'follow':\n",
    "        if data.text == \"Following\":\n",
    "            print(\"You are already following!\")\n",
    "        else:\n",
    "            follow.click()\n",
    "            print(\"Started following\")\n",
    "            \n",
    "    else:\n",
    "        if data.text == \"Following\":\n",
    "            follow.click()\n",
    "            # Now we will unfollow\n",
    "            time.sleep(5)\n",
    "            driver.find_elements(By.XPATH, '//div[contains(@class, \"x9f619 x1n2onr6 x1ja2u2z x1qjc9v5 x78zum5 xdt5ytf x1iyjqo2 xl56j7k xeuugli\")]')[4].click()\n",
    "            print(\"Unfollowed\")\n",
    "        else:\n",
    "            print(\"You have already Unfollowed\")\n",
    "    time.sleep(10)\n",
    "    driver.back()      \n",
    "\n",
    "follow_unfollow(\"sodelhi\", driver, \"unfollow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33563fc",
   "metadata": {},
   "source": [
    "###  FIFTH TASK (LIKE UNLIKE POSTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56db114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n",
      "Already Liked\n"
     ]
    }
   ],
   "source": [
    "def like_unlike(user_handle, driver, params): # where params = like or unlike\n",
    "    search_user(user_handle, driver)\n",
    "    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, '//div[contains(@class, \"_ac7v  _al3n\")]')))\n",
    "    driver.find_element(By.CLASS_NAME, '_aagu').click()\n",
    "\n",
    "    if params == \"Like\":\n",
    "        for i in range(30):\n",
    "            # find innerhtml of the like button so that we can check if it is already liked or not\n",
    "            html = driver.find_element(By.XPATH,\n",
    "                                       '//section[contains(@class, \"_aamu _ae3_ _ae47 _ae48\")]//button').get_attribute('innerHTML')\n",
    "            data = bs(html, \"html.parser\")\n",
    "\n",
    "            if data.title.text == \"Unlike\":# If the title text of like button is unlike print already liked\n",
    "                print(\"Already Liked\")\n",
    "            else:# else if it is not liked then find the like button and click it\n",
    "                driver.find_element(By.XPATH,\n",
    "                                    '//section[contains(@class, \"_aamu _ae3_ _ae47 _ae48\")]//button').click()\n",
    "                \n",
    "            # click the next button\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\n",
    "                                                                        '//button[contains(@class, \"_abl-\")]//*[@aria-label=\"Next\"]'))).click()\n",
    "    else:\n",
    "        for i in range(30):\n",
    "            # find innerhtml of the like button so that we can check if it is already liked or not\n",
    "            html = driver.find_element(By.XPATH,\n",
    "                                       '//section[contains(@class, \"_aamu _ae3_ _ae47 _ae48\")]//button').get_attribute('innerHTML')\n",
    "            data = bs(html, \"html.parser\")\n",
    "\n",
    "            if data.title.text == \"Unlike\":# If the title text of like button is unlike then click it to unlike it\n",
    "                driver.find_element(By.XPATH,\n",
    "                                    '//section[contains(@class, \"_aamu _ae3_ _ae47 _ae48\")]//button').click()\n",
    "                \n",
    "            else:# else if the title text of like button is like then print already unliked\n",
    "                print(\"Already Unliked\")\n",
    "            \n",
    "            #click the next button\n",
    "            WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\n",
    "                                                                        '//button[contains(@class, \"_abl-\")]//*[@aria-label=\"Next\"]'))).click()\n",
    "    driver.back()\n",
    "like_unlike(\"dilsefoodie\", driver, \"Like\")\n",
    "driver.back()\n",
    "driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb27b965",
   "metadata": {},
   "source": [
    "### Sixth Task( Extract username of followers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b65e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_followers(query, driver):\n",
    "    search_user(query, driver)\n",
    "    usernames = []\n",
    "    time.sleep(5)\n",
    "    followers = driver.find_elements(By.XPATH, '//ul[contains(@class, \"x78zum5 x1q0g3np xieb3on\")]//li')[1]\n",
    "    followers.click()\n",
    "    \n",
    "    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CLASS_NAME, \"_aano\")))\n",
    "    \n",
    "    frame = driver.find_element(By.CLASS_NAME, \"_aano\")\n",
    "    cur_height = driver.execute_script('return arguments[0].scrollHeight', frame)\n",
    "\n",
    "    while len(usernames)<500:\n",
    "        x = driver.find_elements(By.XPATH, '//div[contains(@class, \"x9f619 xjbqb8w x1rg5ohu x168nmei x13lgxp2 x5pf9jr xo71vjh x1n2onr6 x1plvlek xryxfnj x1c4vz4f x2lah0s x1q0g3np xqjyukv x6s0dn4 x1oa3qoh x1nhvcw1\")]')\n",
    "        for user in x:\n",
    "            if user.text not in usernames and len(usernames)<500:\n",
    "                usernames.append(user.text)\n",
    "\n",
    "        if len(x) == 50:\n",
    "            break\n",
    "        elif len(x)>500:\n",
    "            break\n",
    "\n",
    "        driver.execute_script('arguments[0].scrollTo(0, arguments[0].scrollHeight)', frame)\n",
    "        time.sleep(2)\n",
    "    return usernames\n",
    "\n",
    "dilsefoodie_followers = extract_followers(\"dilsefoodie\", driver)\n",
    "driver.back()\n",
    "driver.back()\n",
    "sodelhi_followers = extract_followers(\"sodelhi\", driver)\n",
    "driver.back()\n",
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0130f1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DILSEFOODIE FOLLOWERS LIST\n",
      "\n",
      "some_time0912\n",
      "han.ia9321\n",
      "mr._king_31_96\n",
      "__chaitannyyaaa_\n",
      "_the_sirra_\n",
      "couple_goals_600\n",
      "abasitmlt\n",
      "skhan185453\n",
      "amanthakur5693\n",
      "balochsarvarkhan\n",
      "barkha_bhatia_goswami\n",
      "_rao_shabh\n",
      "shopdollarpet\n",
      "iam__asfand\n",
      "engg.ashish03\n",
      "extremefoodievlogs\n",
      "prince_furkan._17\n",
      "happy_attri95\n",
      "naz_capricon_87\n",
      "hemantarora510\n",
      "i_m_inderpreet\n",
      "ikirfankhan00272020\n",
      "irshad3537\n",
      "azha_6053\n",
      "junedjuned3693\n",
      "kuckood\n",
      "aksarlaskor\n",
      "mr_jeeshan_143_\n",
      "anusen007\n",
      "peeyush.mittal8\n",
      "priyankasri.puneet\n",
      "rajkaransingh090201\n",
      "ripon.laskar.3133\n",
      "chasing__my__shadow__alone\n",
      "riyazat_ali_9184\n",
      "rudraverma613\n",
      "m_r_s_i_d_d_h_a_r_t_h\n",
      "sabeenak491\n",
      "aalya_dazzling\n",
      "sagarkhan1234\n",
      "sameenakhatoon289\n",
      "95.48909289\n",
      "shariqqureshi158\n",
      "shary_goyal\n",
      "shivamsahu0716\n",
      "sangeetpandia\n",
      "siddyaaaa\n",
      "harjaivikas\n",
      "vd0301\n",
      "vipul.gamit.1654700\n",
      "\n",
      "\n",
      "SODELHI FOLLOWERS LIST\n",
      "pv18101990\n",
      "sreenidhigroup\n",
      "subgrad\n",
      "akumarspv\n",
      "kantroo_d\n",
      "nehaa24_\n",
      "rohit_francis\n",
      "sushma.pagadala.7\n",
      "saad_sam_shamsi\n",
      "mohd.mohsin_official\n",
      "_lakshyakapur\n",
      "jayan_sodhi\n",
      "deepanshuukumarr\n",
      "__harshvyas_\n",
      "nikhil.gupta_\n",
      "_bhrigusharma_\n",
      "ivairxavier9\n",
      "tadtadkanya\n",
      "harrybabbarr.r\n",
      "neha_ranwa\n",
      "officer_sirr\n",
      "ruc.dua\n",
      "pratham_12400\n",
      "ranjankumar9362\n",
      "sumedhasumit\n",
      "_anupamaa\n",
      "ankitaaa.y_\n",
      "deepaliisshh\n",
      "knavya_78\n",
      "sh3etal09\n",
      "riyyasharma88\n",
      "riyarathore188\n",
      "feliciaalladoum\n",
      "theamantk\n",
      "anjum_tandon_\n",
      "_.appvt1\n",
      "devdkd\n",
      "iamhizabfatima\n",
      "vandana_gupta92\n",
      "a_somya22\n",
      "asl_shabnam\n",
      "arjun.k11117\n",
      "sanjam7cosmos\n",
      "avocadorable_2.0\n",
      "manjot_samra22\n",
      "_saha.indra_\n",
      "thesunrayyyy\n",
      "caprici0ussoul\n",
      "nitya_vyas03\n",
      "ankittanwar333\n",
      "shehla__nigar\n",
      "sim.sim.2003\n",
      "shekhar.h2\n",
      "cie.anurag\n",
      "bataar_1109\n",
      "__sangya6__\n",
      "sachinbajajxd\n",
      "honeyverma7571\n",
      "swarna_1913\n",
      "_ch_anshu_\n",
      "abheyrajmishra\n",
      "mishra.ji.__\n",
      "_sana_malik88\n",
      "dilmeet.rohatgi\n",
      "sapnabains\n",
      "avu_cado\n",
      "tanishaxmalhotra\n",
      "muktapushkarna\n",
      "yashiiigupta\n",
      "aaggarwal390\n",
      "kaaannishka_\n",
      "harsharyapvt\n",
      "dimpyka2011\n",
      "kavyanegi12\n",
      "mathurambika\n",
      "nariyalwala\n",
      "devanshhhhhhhhhhh\n",
      "gita_mnik\n",
      "soloenfrente\n",
      "_ramtaa_jogii\n",
      "a_m_i_t_g_u_p_t_a\n",
      "___its__subur__khan\n",
      "_abhinavshukla\n",
      "theonlykrriti\n",
      "azad_swati\n",
      "arjun1098_\n",
      "_japita\n",
      "prettypriyanka.11.ps\n",
      "__vansh.chauhannn\n",
      "jashn_ee_bahara\n",
      "tropicapixie\n",
      "bidhu_5\n",
      "jha_anmana\n",
      "king__srk___\n",
      "aapki_reach_se_bahar\n",
      "tinytalesindia\n",
      "_.shivang._21\n",
      "yasshvii_._\n",
      "rehan____abid\n",
      "neha_tibrewal_verma\n",
      "aditidalal\n",
      "twinkle.6\n",
      "rizvi.maria98\n",
      "vatsavbeerapalli\n",
      "hi_anniesrivastava\n",
      "ankur.x69\n",
      "winsome_wears23\n",
      "prateek.srivastava04\n",
      "ayushii_633\n",
      "ravi_kumar_kancherla_\n",
      "sahil.srivastav05\n",
      "kaavyabansal_06\n",
      "ankurarora11\n",
      "dr___amir__wasim\n",
      "ruchisuri2\n",
      "_vasu.bansal_\n",
      "_sunshinneee_\n",
      "asigmamindset\n",
      "namratadiddi\n",
      "freesoul_39\n",
      "adarsh____22____07\n",
      "dhruvg_8888\n",
      "manmeet74\n",
      "vibha_malik__\n",
      "_sirishapatil\n",
      "amansingh_.29\n",
      "chandhokparamjitsingh\n",
      "akarsh.mehra\n",
      "meenudabas110039\n",
      "call_me_sashaaaa\n",
      "salonyy.__\n",
      "sachindeshmukh1971\n",
      "_hrithikagrawal\n",
      "dhruvbhaji\n",
      "kamnadhawan4933\n",
      "ladysudan21\n",
      "priyankasoneja\n",
      "vikashgihar16\n",
      "sonuyadav26382\n",
      "brownbetter8\n",
      "_.a.y.u.s.h.i.i._\n",
      "chev_themasterpiece\n",
      "makeadentaman\n",
      "ehehehfathi\n",
      "minikaila\n",
      "nirdosh_ahuja\n",
      "ashmita_2201\n",
      "poonamadhikari_\n",
      "harshitak13_\n",
      "_._arnav_._1\n",
      "lakshitasuteri\n",
      "riabhatnagar2394\n",
      "shivanshkumar8285\n",
      "maverick.rsy\n",
      "1788.pvt\n",
      "hrishit7\n",
      "khalnayak_pintu_01\n",
      "akachandu\n",
      "sarita_sh2512\n",
      "vishakhahahah\n",
      "_snehsss_\n",
      "snehashree178\n",
      "vineet.gurjar_\n",
      "upaliwal24\n",
      "saif_noor777\n",
      "ruchiralhan\n",
      "aaj_ki_nai_khabar\n",
      "adityaxrao7\n",
      "rashiinagpal\n",
      "yuvrajverma_007\n",
      "aayushijha_aj\n",
      "yamini_r_ganotra\n",
      "_the.states_\n",
      "emaadali01\n",
      "kashivashi\n",
      "depak007dk\n",
      "greejestin\n",
      "anshika.jhamb\n",
      "tapan_upmanyu\n",
      "siberfiliak\n",
      "aman_saini_248\n",
      "deeptib01\n",
      "maky999971\n",
      "kamalrai95604749\n",
      "deepasolanki08\n",
      "sonalisingla1993\n",
      "wunder_l_a\n",
      "ajay.rajak5702\n",
      "_siddhigarg\n",
      "monikasharma210183\n",
      "varinkohli\n",
      "alok.kr01\n",
      "riyabhandoria\n",
      "batraneelam86\n",
      "meghakumari021\n",
      "yourhanshika\n",
      "shrishstpp\n",
      "ankit_4854\n",
      "neelamkakkar14\n",
      "sputnik_dreams\n",
      "apna_gurugram_hr_26\n",
      "ishasharma0_0\n",
      "sheeza106\n",
      "atheesh_o_s\n",
      "sananarang._\n",
      "satyam_7535\n",
      "social.nabi_\n",
      "gargi_bindall\n",
      "shivzz03\n",
      "theacidghost42\n",
      "aanchaldubey.714\n",
      "svtu1710\n",
      "ujjwalbrara\n",
      "warrior_eye27\n",
      "ishh_panchal\n",
      "teenu.004\n",
      "shubham_pattanaik\n",
      "shivanikotnala_\n",
      "parukuchhal\n",
      "chetna.singh5740\n",
      "_kitttuuu.24\n",
      "she_blooming_\n",
      "sn3hasingh\n",
      "aashna.______\n",
      "annkitsingh_.04\n",
      "devikasoul\n",
      "shishh.bishh\n",
      "meenu_tyagii\n",
      "cinderellaa__man\n",
      "traditionsbypoojabackliwal\n",
      "pb29chef\n",
      "aadityapai\n",
      "baqar_usmani\n",
      "lovekeshchopra_1990\n",
      "sakshii01___\n",
      "anand23sindhu\n",
      "rockybhai_647\n",
      "arpitgkp.0007\n",
      "akanksha_shrivastava14\n",
      "_.salonigargg._\n",
      "mmatanhelia\n",
      "mavimanisha_1\n",
      "__vaniii.poudwal_\n",
      "rjchopra13\n",
      "tapasmajumder2007\n",
      "jemal_desai\n",
      "preet_gill9491\n",
      "neer352\n",
      "harsh_behrani\n",
      "ruchikaa.khera\n",
      "shelly884\n",
      "christinaaaaa_10\n",
      "_mommadememories\n",
      "kittu_.1111\n",
      "maa__ka__ladale\n",
      "himaninainwal19\n",
      "kushikaabajaj\n",
      "the_wierd_one230e\n",
      "shrutibansal08\n",
      "ravijoon93\n",
      "shreya_singh0972\n",
      "milinagpal\n",
      "bakers_bay80\n",
      "monika.chaudhary72700\n",
      "dulhanboutiq\n",
      "sidhu_sangram\n",
      "the.one.she._\n",
      "deepakgrewal22\n",
      "rudransh_dubey10\n",
      "29_muskan_khurana_\n",
      "ar.aanchal_thaman\n",
      "insta_offisl_king_01\n",
      "yayavar_raahi\n",
      "thelostsoul_3\n",
      "anonymous_aspirant123\n",
      "shardulkanase\n",
      "not__funny__at__all\n",
      "renukabishtxx\n",
      "photodooom\n",
      "pahaadibong\n",
      "vaish_alid\n",
      "kumarpatel6970amit\n",
      "s.gupta1310\n",
      "saini_love1007\n",
      "iamyasirrr\n",
      "ana_110365\n",
      "nature_resl\n",
      "_harshitajoshi_\n",
      "aazaadi_\n",
      "sumonachakravarty\n",
      "_.arpitmehta._\n",
      "officalpage_of_vip\n",
      "dani444.jpeg\n",
      "muskaann_04\n",
      "aanchal2458\n",
      "freakynaughtyadultboy_69\n",
      "leovazze\n",
      "jas_kaur9\n",
      "deepakpant00\n",
      "mandeepsinghchadha\n",
      "kiran_k1265\n",
      "prabhleen_johar\n",
      "asmitaanand_\n",
      "tanishq_gupta_\n",
      "abuzz_er\n",
      "dhruvgoel_17\n",
      "msdd07\n",
      "shivvv.m___\n",
      "gurasishc\n",
      "pratibhaaaa._\n",
      "combat.connoisseur\n",
      "camay1camay_5\n",
      "vrinda.maan\n",
      "rajendrasgems\n",
      "rinky_manwani\n",
      "sudeepsukla\n",
      "exoticankita\n",
      "chaimeindoobabiskut\n",
      "gracyjainn\n",
      "jain_sujat\n",
      "chanoeyyyy\n",
      "awesomeabhiagra\n",
      "diwakarnc\n",
      "hermione6191\n",
      "znattt_\n",
      "elinakanodia\n",
      "high_on_chai0\n",
      "kamal_agrawal015\n",
      "parv050\n",
      "tannu_panwar_16\n",
      "tanya.lekhi.528\n",
      "kapoormrinal\n",
      "puneett86\n",
      "prateekramrakhyani\n",
      "gurleen6472\n",
      "mr_and_mrs_kharbanda\n",
      "__kashish.gupta__\n",
      "i.qwerty78\n",
      "shknny777\n",
      "ijaz84191gmail.com_\n",
      "avanivijayy_\n",
      "abhash79\n",
      "aniket_gulati20\n",
      "pintukumar780____indian\n",
      "suchitra.1980\n",
      "vk1765548\n",
      "abhishek_sinha13\n",
      "vanshika1613\n",
      "kohi_bajaj\n",
      "armaan.sethi\n",
      "anjula.narang\n",
      "simmu_0211\n",
      "rashi.4509\n",
      "smartcollection730\n",
      "rajat.singhofficial\n",
      "ninjatodwal\n",
      "over__d__moon\n",
      "ehteshamakhter786\n",
      "avnii.456\n",
      "rishita_ig\n",
      "vaishnavimalhotra.23\n",
      "muskan_chhabra_98\n",
      "ojayykayy\n",
      "monicarawall\n",
      "mayakrishnanofficial\n",
      "mr_tushar_kr\n",
      "supriya.mehrotra\n",
      "anuj.chopra87\n",
      "geetikabhan21\n",
      "bhavesh_malik01\n",
      "_kittu_gaharwar_\n",
      "kriti_2804\n",
      "ek.ta708\n",
      "miteshjajodia\n",
      "babitaverma1566\n",
      "anshul_07dec\n",
      "deepanshugarg15\n",
      "kbhavya706\n",
      "varma_6682\n",
      "kayy_jayyy_\n",
      "prernak_5\n",
      "sahilkumar_11\n",
      "ansarinooh\n",
      "dipikachichani\n",
      "anmritaakaur\n",
      "bhardwaj96_kartik\n",
      "ankitacss\n",
      "nikhil.behal_\n",
      "shekhar_thathera\n",
      "swechha_singh_07\n",
      "sachinsoodloni\n",
      "umangallagh\n",
      "mayank_shukla21\n",
      "ashuaman04\n",
      "yaashica_chaudhary\n",
      "hiranjana_s\n",
      "dr.kaviyaoberoi\n",
      "manishchikku\n",
      "yyatin.dapper\n",
      "sangeetas252\n",
      "prekshaachauhan\n",
      "celery_made\n",
      "jitenderrrrr\n",
      "karansharma_2601\n",
      "_dikshadadu_\n",
      "uday_tanwar_\n",
      "saniyajain94\n",
      "kaavko\n",
      "rai_om99\n",
      "ritiikaaraj\n",
      "ca_sumitchauhan\n",
      "kmr_abhshk_mishra\n",
      "_rozina_sheikh_\n",
      "ajeet.sonika\n",
      "khera.nancy\n",
      "harshayayay\n",
      "amrinder_singh3636\n",
      "kajaljha_kj_\n",
      "deek_s\n",
      "tim.matsuda01\n",
      "sweety_saini12\n",
      "yours_trulyjaved\n",
      "harpreetkaur1379\n",
      "harshit.kwatra\n",
      "bellak2011\n",
      "annanya_28\n",
      "em.jayyyyy\n",
      "___golu_911\n",
      "justchilldreams\n",
      "vaishnvi_222\n",
      "kuuuunaaallll\n",
      "mitulbansal7\n",
      "gauravryon\n",
      "_arif__s\n",
      "kavitabisht418\n",
      "aniketjainsj\n",
      "lesyeuxderay_\n",
      "jyoti_yadav____\n",
      "utkamishh\n",
      "vishalalterego\n",
      "guptaneha.8714\n",
      "jain.samyak15\n",
      "dinwal3\n",
      "lavanyasamad_\n",
      "radhikamanhas9889\n",
      "north_campus_family\n",
      "eklavya_rexwal28\n",
      "kiran_khatri17\n",
      "_lazana_\n",
      "rpsjaswal\n",
      "sushant868462\n",
      "shopmall004\n",
      "beyond_that_shit\n",
      "jnhv_2\n",
      "mrs_manchanda\n",
      "_.ragini._._\n",
      "gian.ganda\n",
      "mihirdhingra99\n",
      "aj.mg1231\n",
      "_iinsiya_\n",
      "sidhant_dhall\n",
      "_akash___1994\n",
      "guptanavdeeep\n",
      "econedventure\n",
      "purnima_malhotra_\n",
      "mehakpreet15\n",
      "a.yashwanth090\n",
      "akhilx404\n",
      "saranyagupta05\n",
      "itzwht.itz\n",
      "_shayan_10_\n",
      "veeeeeeewwwww\n",
      "_rihabkhan0001\n",
      "never_gonnalie29\n",
      "abhisekmishra922\n",
      "anitaagrawaljain\n",
      "pratishthaaa_20\n",
      "tajinderkaur777\n",
      "lysrii8\n",
      "prakashmaurya8872\n",
      "its_prabh_112\n",
      "ssuunnyy7777\n",
      "praagyaa_shaarmaa\n",
      "piyushndream\n",
      "anagha_10\n",
      "_kanhiaya_garg\n",
      "pingku303\n",
      "pranayahuja95\n",
      "huraira_khan_add_12324\n",
      "harshita.tailang\n",
      "motivational.quotes__poetry\n",
      "saumyasamridhi\n",
      "aniket_aka_annu\n",
      "kartikwadhwaa\n",
      "basic.photographer12\n",
      "vickyshah827\n",
      "ex__shivaa\n",
      "dhwani._.sadija\n",
      "deepa__ddm\n",
      "akshita_bisht_07\n"
     ]
    }
   ],
   "source": [
    "print(\"DILSEFOODIE FOLLOWERS LIST\\n\")\n",
    "for user in dilsefoodie_followers: # printing dilsefoodie followers \n",
    "    print(user)\n",
    "print(\"\\n\")\n",
    "print(\"SODELHI FOLLOWERS LIST\") # printing sodelhi followers\n",
    "for user in sodelhi_followers:\n",
    "    print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92483b5",
   "metadata": {},
   "source": [
    "### Seventh Task (CHECK STORY OF CODING NINJAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6a6cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are stories But You have Already Seen all the story!\n"
     ]
    }
   ],
   "source": [
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "\n",
    "def check_story(query, driver):\n",
    "    search_user(query, driver)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    ifstory = driver.find_element(By.XPATH, '//div[contains(@class, \"_aarf\")]')# to check if there is story or not\n",
    "    \n",
    "    if ifstory.get_attribute('aria-disabled') == 'false':\n",
    "        print(\"There are stories\",end = \"\")\n",
    "        time.sleep(2)\n",
    "        # to check if you have seen all the stories or not\n",
    "        height = int(driver.find_element(By.XPATH, '//div[contains(@class, \"_aarf _aarg\")]/canvas').get_attribute('height'))\n",
    "        if height == 166:\n",
    "            print(\" But You have Already Seen all the story!\")\n",
    "        else:\n",
    "            see_story = driver.find_element(By.XPATH, '//div[contains(@class, \"_aarf _aarg\")]')# to click on stories\n",
    "            see_story.click()\n",
    "            time.sleep(3)\n",
    "            \n",
    "            num_of_story = driver.find_elements(By.XPATH, '//div[contains(@class, \"_ac3r\")]/div')# to check how many stories are there\n",
    "            \n",
    "            next_button = driver.find_element(By.CLASS_NAME, \"_ac0d\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                # Check if the element is visible\n",
    "                if driver.find_element(By.CLASS_NAME, \"_ac0d\").is_displayed():\n",
    "                    next_button.click()\n",
    "            except (StaleElementReferenceException, NoSuchElementException):\n",
    "                break\n",
    "\n",
    "    else:\n",
    "        print(\"There are no stories\")\n",
    "        \n",
    "check_story(\"coding.ninjas\", driver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0fd7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
